# vLLM Model Configuration
VLLM_MODEL=Qwen/Qwen3-32B-AWQ
VLLM_TENSOR_PARALLEL_SIZE=2
VLLM_GPU_MEMORY_UTILIZATION=0.80
VLLM_MAX_MODEL_LEN=32768
VLLM_DTYPE=auto
VLLM_QUANTIZATION=awq
VLLM_MAX_NUM_SEQS=256

# NCCL Configuration (CRITICAL for RTX 5090 Dual GPU)
NCCL_VERSION=2.27.7-1+cuda12.9
NCCL_IB_DISABLE=1
NCCL_P2P_DISABLE=0
NCCL_DEBUG=WARN

# PageIndex Configuration
PAGEINDEX_VLLM_ENDPOINT=http://vllm:8000
PAGEINDEX_MODEL_NAME=Qwen/Qwen3-32B-AWQ

# Application Configuration
NODE_ENV=production
PORT=3000
LOG_LEVEL=info

# Optional: HuggingFace Token (only if using gated/private models)
# HF_TOKEN=your_huggingface_token_here
